{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developmental-floor",
   "metadata": {},
   "source": [
    "# Contact Fingerprint Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floral-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers, regularizers, optimizers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-gravity",
   "metadata": {},
   "source": [
    "### Defining utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 96\n",
    "\n",
    "def load_data(path, altered=True):\n",
    "    \"\"\" Loads the fingerprint images.\n",
    "    \n",
    "    Args:\n",
    "        path (str): path containing the fingerprint images\n",
    "        altered (bool): altered or original fingerprint images (default=True)\n",
    "        \n",
    "    Returns:\n",
    "        data (list): dataset of fingerprint images (user_id, fingernumber, image) \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading data from: \", path)\n",
    "    data = []\n",
    "    for img in os.listdir(path):\n",
    "        imgname, ext = os.path.splitext(img)\n",
    "        ID, etc = imgname.split('__')\n",
    "        \n",
    "        # Decrementing id by 1 (to_categorical encodes starting from 0)\n",
    "        ID = int(ID) - 1\n",
    "        \n",
    "        # Extracting hand and finger information (altered images have additional info - type of modification)\n",
    "        if altered:\n",
    "            _, hand, finger, _, _ = etc.split('_')\n",
    "        else:\n",
    "            _, hand, finger, _  = etc.split('_')\n",
    "        \n",
    "        # Encoding fingers (left hand corresponding to 0-4 and right hand corresponding to 5-9)\n",
    "        if hand=='Left':\n",
    "            base = 0\n",
    "        else: base  = 5\n",
    "        if finger==\"little\":\n",
    "            fingerNum = base + 0\n",
    "        elif finger=='ring':\n",
    "            fingerNum = base + 1\n",
    "        elif finger=='middle':\n",
    "            fingerNum = base + 2\n",
    "        elif finger=='index':\n",
    "            fingerNum = base + 3 \n",
    "        else: fingerNum = base + 4\n",
    "        \n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        img_resize = cv2.resize(img_array, (img_size, img_size))\n",
    "        data.append([ID, fingerNum, img_resize])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sized-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    " def display_header(text):\n",
    "    header = \"-- \" + text + \" --\"\n",
    "    print(\"-\"*len(header))\n",
    "    print(header)\n",
    "    print(\"-\"*len(header)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-sending",
   "metadata": {},
   "source": [
    "## 1. Loading fingerprint data\n",
    "___\n",
    "\n",
    "We have 4 folders containing fingerprint images:\n",
    "- Altered-Easy\n",
    "- Altered-Medium\n",
    "- Altered-Hard\n",
    "- Real\n",
    "\n",
    "Let's load each one of them using the `load_data` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ignored-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ../data/SOCOFing/Altered/Altered-Easy\n",
      "Loading data from:  ../data/SOCOFing/Altered/Altered-Medium\n",
      "Loading data from:  ../data/SOCOFing/Altered/Altered-Hard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ../data/SOCOFing/Real\n"
     ]
    }
   ],
   "source": [
    "altered_images_path = \"../data/SOCOFing/Altered/Altered-\"\n",
    "real_images_path = \"../data/SOCOFing/Real\"\n",
    "\n",
    "# Loading the altered data\n",
    "easy_data = load_data(altered_images_path+'Easy', altered=True)\n",
    "medium_data = load_data(altered_images_path+'Medium', altered=True)\n",
    "hard_data = load_data(altered_images_path+'Hard', altered=True)\n",
    "\n",
    "# Concatenating altered data\n",
    "altered_data = np.concatenate([easy_data, medium_data, hard_data], axis=0, dtype=\"object\")\n",
    "\n",
    "# Freeing memory\n",
    "del easy_data, medium_data, hard_data\n",
    "\n",
    "# Loading the real data\n",
    "real_data = np.array(load_data(real_images_path, altered=False), dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amino-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "-- Number of samples --\n",
      "-----------------------\n",
      "\n",
      "Altered data: 49270\n",
      "Real data:    6000\n"
     ]
    }
   ],
   "source": [
    "display_header(\"Number of samples\")\n",
    "print(f\"Altered data: {len(altered_data)}\")\n",
    "print(f\"Real data:    {len(real_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electronic-charlotte",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'real_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e7d67e46a6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Counting unique users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There are {num_classes} unique user_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'real_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Counting unique users\n",
    "num_classes = len(np.unique(real_data[:, 0]))\n",
    "print(f\"There are {num_classes} unique user_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-tracy",
   "metadata": {},
   "source": [
    "## 2. Creating the Datasets\n",
    "___\n",
    "\n",
    "Here, we'll create datasets for training, validating and testing our model.\n",
    "\n",
    "The altered data will be used for training and validating, and the real data will be used for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-coordinate",
   "metadata": {},
   "source": [
    "- **Creating the training and validation datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "leading-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_altered, y_subjectID_altered = [], []\n",
    "\n",
    "for subjectID, _, feature in altered_data:\n",
    "    X_altered.append(feature)\n",
    "    y_subjectID_altered.append(subjectID)\n",
    "\n",
    "X_altered = np.array(X_altered).reshape(-1, img_size, img_size, 1)\n",
    "X_altered = X_altered / 255.0  # Normalizing to [0, 1] \n",
    "y_subjectID_altered = to_categorical(y_subjectID_altered, num_classes=num_classes)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_altered, y_subjectID_altered, test_size=0.2, random_state=2)\n",
    "\n",
    "# Freeing memory\n",
    "del altered_data, X_altered, y_subjectID_altered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-maryland",
   "metadata": {},
   "source": [
    "- **Creating the testing dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "german-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the testing dataset\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for subjectID, _, feature in real_data:\n",
    "    X_test.append(feature)\n",
    "    y_test.append(subjectID)\n",
    "\n",
    "X_test = np.array(X_test).reshape(-1, img_size, img_size, 1)\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Freeing memory\n",
    "del real_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-index",
   "metadata": {},
   "source": [
    "- **Visualizing data split:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "intelligent-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Split           Feature shape      label shape\n",
      "------------------------------------------------\n",
      " Train:       (39416, 96, 96, 1)    (39416, 600)\n",
      " Validation:  (9854, 96, 96, 1)     (9854, 600)\n",
      " Test:        (6000, 96, 96, 1)     (6000, 600)\n"
     ]
    }
   ],
   "source": [
    "print(\" Split           Feature shape      label shape\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\" Train:       {str(X_train.shape):<18}    {y_train.shape}\")\n",
    "print(f\" Validation:  {str(X_val.shape):<18}    {y_val.shape}\")\n",
    "print(f\" Test:        {str(X_test.shape):<18}    {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-uncertainty",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-citizenship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
